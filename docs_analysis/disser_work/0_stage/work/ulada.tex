\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{hyperref}
\geometry{left=25mm, right=25mm, top=25mm, bottom=25mm}

\title{\textbf{Unified Layer Anomaly Detection Algorithm}}
\author{ }
\date{}

\begin{document}
\maketitle

\section{Постановка задачи и обоснованность алгоритма}

Рассматривается задача поиска закономерностей, позволяющих определить, какой слой нейронной сети негативно влияет на общий инференс модели. При плохой сходимости сети необходимо выявить \emph{проблемные} слои, у которых параметры либо недостаточно экспрессивны, либо их обновления характеризуются чрезмерной нестабильностью. Для решения данной задачи предлагается алгоритм ULADA (Unified Layer Anomaly Detection Algorithm), который объединяет два строго математически обоснованных подхода:
\begin{itemize}[leftmargin=1.0cm]
    \item анализ локальных гессианов с вычислением спектральных характеристик и меры эффективного ранга;
    \item исследование динамики оптимизации через риманову геометрию параметрического пространства, включающее вычисление натурального градиента, геодезических линий и оценку кривизны.
\end{itemize}

Выбранный алгоритм решает поставленную задачу за счёт комплексной диагностики каждого слоя с использованием как статических характеристик (спектральное распределение гессиана, концентрация собственных значений), так и динамических (изменение траекторий оптимизации в римановом пространстве). Такой комбинированный подход позволяет однозначно интерпретировать причины плохой сходимости, выделяя слои, в которых неадекватное использование параметрического пространства или аномально высокая кривизна ведут к нарушению стабильности инференса модели. В итоге формируется основа для рекомендации корректирующих мер, таких как адаптация гиперпараметров или изменение архитектурных особенностей.

После подробного обоснования данной методики переходим к описанию полного математического аппарата, на котором строится алгоритм ULADA.

\bigskip

\section{Полный математический аппарат}

В данном разделе представлена полная версия математического аппарата, лежащего в основе алгоритма ULADA. Аппарат состоит из нескольких этапов: декомпозиция нейросети, вычисление локальных гессианов, спектральный анализ, введение меры эффективного ранга, а также риманово-геометрический анализ динамики оптимизации.

\subsection*{1. Декомпозиция нейросети и вычисление локальных гессианов}

Нейросеть \( F(x;\theta) \) представляется как композиция функциональных блоков (слоёв):
\[
F(x;\theta) = \big( C_n \circ C_{n-1} \circ \cdots \circ C_1 \big)(x),
\]
где каждый слой \( C_i \) определяется парой модулей \((P_i, A_i)\) с параметрами слоя \(\theta_i\), где \(P_i\) и \(A_i\) --- компоненты i-го слоя.

Для каждого слоя вводится скалярная функция:
\[
S_i(\theta_i) = \varphi\Bigl(A_i\bigl(P_i(z_i;\theta_i)\bigr)\Bigr),
\]
где \( z_i \) --- вход данного слоя, а функция агрегации \(\varphi\) (например, суммирование компонентов) обеспечивает сведение выходного вектора к скаляру.

Вычисляются:
\[
g_i = \nabla_{\theta_i} S_i,
\]
а затем локальная матрица Гессе:
\[
H_i = \nabla^2_{\theta_i} S_i, \quad \text{где } H_i[j,k] = \frac{\partial^2 S_i}{\partial \theta_{i,j}\partial \theta_{i,k}}.
\]

\subsection*{2. Спектральный анализ и мера эффективного ранга}

Для каждого слоя проводится спектральное разложение гессиана:
\[
H_i = U_i\,\Lambda_i\,U_i^\top,
\]
где \(\Lambda_i = \operatorname{diag}(\lambda_{i,1}, \lambda_{i,2}, \dots, \lambda_{i,p_i})\) --- диагональная матрица, содержащая собственные значения, а \(p_i\) --- число параметров в слое.

Определяется мера эффективного ранга:
\[
r_{\text{eff}}^{(i)} = \frac{\left(\sum_{j=1}^{p_i} \lambda_{i,j}\right)^2}{\sum_{j=1}^{p_i}\lambda_{i,j}^2}.
\]
Нормировка меры производится по формуле:
\[
\hat{r}_{\text{eff}}^{(i)} = \frac{r_{\text{eff}}^{(i)} - 1}{p_i - 1}.
\]
Значение \(\hat{r}_{\text{eff}}^{(i)}\) принимает значение от 0 до 1, где \(\hat{r}_{\text{eff}}^{(i)} \approx 0\) соответствует сильной концентрации всех собственных значений в одном направлении (underparameterization), а \(\hat{r}_{\text{eff}}^{(i)} \approx 1\) --- равномерному распределению (overparameterization).\\\\
Введем пороги для нормированного эффективного ранга, например:
\begin{itemize}[leftmargin=0.5cm]
    \item Если \(\hat{r}_{\text{eff}}^{(i)} < 0.2\) – слой считается \textbf{underparameterized}, т.е. недостаточно активное, что может указывать на \textit{узкое место};
    \item Если \(\hat{r}_{\text{eff}}^{(i)} > 0.8\) – слой считается \textbf{overparameterized}, т.е. слишком равномерное распределение, потенциально приводящее к переобучению.
\end{itemize}

\subsection*{3. Риманова геометрия и анализ динамики оптимизации}

Параметрическое пространство каждого слоя рассматривается как гладкое многообразие с римановой метрикой, заданной Фишеровой информацией:
\[
g^{(i)}_{ij}(\theta_i) = \mathbb{E}\left[\frac{\partial \log p(x;\theta)}{\partial \theta_{i}} \frac{\partial \log p(x;\theta)}{\partial \theta_{j}}\right].
\]
С учётом данной метрики определяется \emph{натуральный градиент}:
\[
\tilde{\nabla} L^{(i)} = \bigl(g^{(i)}(\theta_i)\bigr)^{-1}\nabla_{\theta_i} L,
\]
где \( L(\theta) \) --- функция потерь.

Для описания траекторий обновления параметров вводятся геодезические линии, удовлетворяющие уравнению:
\[
\frac{d^2\gamma^{(i)}_k}{dt^2} + \Gamma^{(i),k}_{jl}\,\frac{d\gamma^{(i)}_j}{dt}\,\frac{d\gamma^{(i)}_l}{dt} = 0,
\]
где символы Кристоффеля вычисляются по формуле:
\[
\Gamma^{(i),k}_{jl} = \frac{1}{2}\sum_{m}\left(g^{(i)}\right)^{km}\Bigl(\partial_j g^{(i)}_{lm} + \partial_l g^{(i)}_{jm} - \partial_m g^{(i)}_{jl}\Bigr).
\]
На основании этих данных можно вычислить риманов тензор кривизны:
\[
R^{(i),l}_{\quad ijk} = \partial_j \Gamma^{(i),l}_{ik} - \partial_i \Gamma^{(i),l}_{jk} + \Gamma^{(i),l}_{jm}\,\Gamma^{(i),m}_{ik} - \Gamma^{(i),l}_{im}\,\Gamma^{(i),m}_{jk}.
\]
Оценка норм или других характеристик кривизны \(\|R^{(i)}\|\) позволяет количественно описать локальное «изгибание» пространства параметров и выявить нестабильность оптимизации.

\subsection*{4. Объединённый индикатор аномалий}

Для интеграции результатов статического и динамического анализа вводится объединённый индикатор аномалий для слоя:
\[
A^{(i)} = w_1 \cdot f\bigl(\hat{r}_{\text{eff}}^{(i)}\bigr) + w_2 \cdot h\bigl(\|R^{(i)}\|\bigr),
\]
где:
\begin{itemize}[leftmargin=1.5cm]
    \item \( f \) --- функция нормировки меры эффективного ранга, отображающая значения из \([0,1]\) в единичный интервал;
    \item \( h \) --- функция, нормирующая характеристику кривизны;
    \item \( w_1 \) и \( w_2 \) --- весовые коэффициенты, определяемые экспериментально.
\end{itemize}

Если значение \( A^{(i)} \) превышает выбранный порог \(\tau\), слой считается аномальным, что свидетельствует о негативном влиянии данного слоя на общий инференс. При этом анализ отдельных вкладов \( f\bigl(\hat{r}_{\text{eff}}^{(i)}\bigr) \) и \( h\bigl(\|R^{(i)}\|\bigr) \) позволяет уточнить, вызвана ли проблема недостаточным использованием параметрического пространства или чрезмерной нестабильностью геометрии.

Эта подробная трактовка математического аппарата обеспечивает строгое обоснование диагностического алгоритма и служит основой для практической интерпретации результатов оптимизации сети.

\bigskip

\section{Рекомендации и предостережения}

Применение алгоритма ULADA требует внимания к следующим аспектам:
\begin{itemize}[leftmargin=1.5cm]
    \item \textbf{Корректность вычислений:} Необходимо обеспечить, чтобы аппроксимации спектрального разложения и римановой метрики не приводили к существенным погрешностям в оценке мер эффективности и кривизны.
    \item \textbf{Адаптация пороговых значений:} Хотя предложенные значения порогов (например, \(0.2\) и \(0.8\) для нормированного эффективного ранга) являются обоснованными теоретически, их следует адаптировать к конкретной архитектуре сети и характеру обучающего процесса.
    \item \textbf{Интеграция в процесс обучения:} Для динамического мониторинга состояния сети рекомендуется периодически вычислять индикаторы \( A^{(i)} \) и осуществлять обратную связь, корректируя гиперпараметры (например, шаг обучения или коэффициенты регуляризации) для проблемных слоёв.
    \item \textbf{Визуализация и интерпретация:} Разработка специализированного интерфейса для визуализации динамики спектральных характеристик и кривизны позволит более наглядно интерпретировать результаты и принимать обоснованные решения по оптимизации модели.
\end{itemize}

Алгоритм ULADA является диагностическим инструментом, направленным на выявление аномальных состояний в отдельных слоях. Его применение должно предварительно сопровождаться эмпирической валидацией, что позволит уточнить оптимальные настройки и адаптировать методику под особенности конкретной архитектуры. Такой комплексный подход обеспечивает целостное понимание динамики обучения, позволяя не только обнаруживать ``узкие места'' в сети, но и предлагать конкретные меры по их корректировке, способствуя улучшению качества инференса.

\bigskip

\section{Рекомендация: Оптимизированная версия ULADA}

Данный раздел посвящён оптимизации вычислительной сложности исходного алгоритма, сохраняя при этом достаточную точность для диагностики слоёв с размерностью до 10\,000 параметров. Предлагается применение аппроксимаций, позволяющих перейти от кубической или квадратной сложности к линейной.

\subsection*{Аппроксимация вычисления гессиана}

\textbf{Исходный вариант:} Полный гессиан \( H_i \) вычисляется с затратами \( O(p_i^2) \) по памяти и операций, где \( p_i \) --- число параметров слоя.

\textbf{Аппроксимация:}
\begin{itemize}
    \item \emph{Диагональное приближение:} Вместо полного гессиана вычисляются только диагональные элементы \( H_i[j,j] \), что снижает вычислительную сложность до \( O(p_i) \).
    \item \emph{Метод случайных векторных произведений (Hutchinson’s estimator):} Оцениваются следовые показатели \(\text{tr}(H_i)\) и \(\text{tr}(H_i^2)\) за \( K \) итераций, где \( K \) --- небольшое число (например, 5--10). Это позволяет аппроксимировать меру эффективного ранга без полного спектрального разложения.
\end{itemize}

\subsection*{Аппроксимация спектрального анализа}

\textbf{Исходный вариант:} Полное спектральное разложение \( H_i = U_i\,\Lambda_i\,U_i^\top \) требует \( O(p_i^3) \) операций.

\textbf{Аппроксимация:}
\begin{itemize}
    \item Использование итеративных методов (например, power iteration или метод Ленцоса) для вычисления лишь нескольких \( k \ll p_i \) наибольших собственных значений.
    \item Применение оценок следа через Hutchinson’s estimator для приближённого вычисления:
    \[
    \widehat{r}_{\text{eff}}^{(i)} \approx \frac{\Big(\widehat{\text{tr}}(H_i)\Big)^2}{\widehat{\text{tr}}(H_i^2)},
    \]
    с последующей нормировкой:
    \[
    \hat{r}_{\text{eff}}^{(i)} = \frac{\widehat{r}_{\text{eff}}^{(i)} - 1}{p_i - 1}.
    \]
\end{itemize}
Эта аппроксимация имеет линейную сложность \( O(p_i) \) по каждому слою.

\subsection*{Аппроксимация вычисления римановой геометрии}

\textbf{Исходный вариант:} Полное вычисление Фишеровой матрицы, её обращение и интегрирование уравнений геодезических требует значительных вычислительных ресурсов.

\textbf{Аппроксимация:}
\begin{itemize}
    \item Применение блочного (или диагонального) приближения Фишеровой матрицы, аналогичного методу K-FAC, что позволяет эффективно решать задачу обращения матрицы.
    \item Использование локально-линейного предположения для аппроксимации символов Кристоффеля \(\hat{\Gamma}^{(i)}\) с вычислением локальной кривизны \(\| \hat{R}^{(i)} \|\) по конечным разностям или за ограниченное число шагов.
\end{itemize}
Данные аппроксимации позволяют снизить сложность до порядка \( O(1) \)–\( O(p_i) \) при ограниченном числе итераций и обеспечить параллельное выполнение для каждого слоя.

\subsection*{Объединённый оптимизированный алгоритм}

\textbf{Пошаговый алгоритм:}

\begin{enumerate}
    \item \textbf{Декомпозиция сети:} Разбиваем нейросеть \( F(x;\theta) \) на слои \( C_i \) с параметрами \(\theta_i\).
    \item \textbf{Аппроксимированное вычисление гессиана:} Для каждого слоя:
    \begin{itemize}
        \item Вычисляем скалярную функцию \( S_i(\theta_i) \).
        \item Аппроксимируем гессиан \( H_i \) посредством диагонального приближения или с помощью случайных векторных произведений для оценки \(\widehat{\text{tr}}(H_i)\) и \(\widehat{\text{tr}}(H_i^2)\).
    \end{itemize}
    \item \textbf{Аппроксимированный спектральный анализ:} Рассчитываем приближённую меру эффективного ранга:
    \[
    \widehat{r}_{\text{eff}}^{(i)} \approx \frac{\Big(\widehat{\text{tr}}(H_i)\Big)^2}{\widehat{\text{tr}}(H_i^2)},
    \]
    с последующей нормировкой:
    \[
    \hat{r}_{\text{eff}}^{(i)} = \frac{\widehat{r}_{\text{eff}}^{(i)} - 1}{p_i - 1}.
    \]
    \item \textbf{Аппроксимированное вычисление римановой метрики:} Для каждого слоя оцениваем блочную или диагональную Фишерову матрицу \( \hat{g}^{(i)} \) и вычисляем натуральный градиент:
    \[
    \tilde{\nabla} L^{(i)} \approx \big(\hat{g}^{(i)}\big)^{-1}\nabla_{\theta_i} L.
    \]
    \item \textbf{Аппроксимированное моделирование геодезических линий:} С использованием локально-линейного предположения вычисляем аппроксимированные символы Кристоффеля \(\hat{\Gamma}^{(i)}\) и оцениваем локальную кривизну \(\|\hat{R}^{(i)}\|\) за ограниченное число шагов.
    \item \textbf{Формирование объединённого индикатора аномалий:} Определяем аппроксимированный индикатор:
    \[
    \hat{A}^{(i)} = w_1 \cdot f\big(\hat{r}_{\text{eff}}^{(i)}\big) + w_2 \cdot h\big(\|\hat{R}^{(i)}\|\big),
    \]
    где при \( \hat{A}^{(i)} > \tau \) слой считается проблемным.
    \item \textbf{Адаптивная коррекция:} На основании полученных индикаторов корректируем гиперпараметры (шаг обучения, регуляризацию) или архитектуру проблемных слоёв.
\end{enumerate}

\subsection*{Анализ вычислительной сложности и параллелизации}

Благодаря предложенным аппроксимациям:
\begin{itemize}
    \item Оценка гессиана с использованием диагонального приближения или метода Hutchinson’а имеет сложность \( O(p_i) \) для слоя с \( p_i \) параметрами.
    \item Аппроксимация спектрального анализа также сводится к \( O(p_i) \), поскольку используются трасс-оценки.
    \item Обращение блочной Фишеровой матрицы или её диагонального приближения обеспечивает линейную сложность.
    \item Локальное моделирование геодезических линий проводится за ограниченное число итераций, что допускает сложность \( O(1) \)–\( O(p_i) \).
\end{itemize}
Таким образом, суммарная сложность по каждому слою составляет \( O(p_i) \) и, при параллельном выполнении для всех слоёв, общая сложность алгоритма для сети с \( N \) параметрами равна \( O(N) \). Данные оптимизации обеспечивают значительное снижение вычислительной сложности без потери точности, что позволяет применять алгоритм для анализа слоёв с несколькими десятками параметров. Параллелизация каждого этапа дополнительно улучшает производительность и делает алгоритм пригодным для использования в современных архитектурах.

\begin{algorithm}
\caption{ULADA (Unified Layer Anomaly Detection Algorithm)}
\label{alg:ulada}
\begin{algorithmic}[1]

\Require Нейросеть $F$, обучающая выборка, функция потерь $L(\theta)$
\Ensure Индикаторы аномалий $\hat{A}^{(i)}$ по слоям и рекомендации по корректировке

\Statex

\State \textbf{Шаг 1: Декомпозиция сети и вычисление локальных гессианов}
\State Разбить сеть $F$ на слои $C_i$ с параметрами $\theta_i$
\For{каждый слой $i$}
  \State Вычислить скалярную функцию $S_i(\theta_i)$
  \State Вычислить градиент $g_i \gets \nabla_{\theta_i} S_i$
  \State Вычислить (аппроксимированный) гессиан $\hat{H}_i \gets \nabla^2_{\theta_i} S_i$ (с диагональным приближением или Hutchinson’s estimator)
\EndFor

\Statex

\State \textbf{Шаг 2: Спектральный анализ и эффективный ранг}
\For{каждый слой $i$}
  \State Используя $\hat{H}_i$, оценить $\widehat{\mathrm{tr}}(H_i)$ и $\widehat{\mathrm{tr}}(H_i^2)$
  \State $\widehat{r}_{\text{eff}}^{(i)} \gets \Big(\widehat{\mathrm{tr}}(H_i)\Big)^2 \,/\, \widehat{\mathrm{tr}}(H_i^2)$
  \State $\hat{r}_{\text{eff}}^{(i)} \gets \big(\widehat{r}_{\text{eff}}^{(i)} - 1\big)\,/\,\big(p_i - 1\big)$
\EndFor

\Statex

\State \textbf{Шаг 3: Аппроксимация римановой геометрии}
\For{каждый слой $i$}
  \State $\hat{g}^{(i)} \gets$ аппроксимированная Фишерова матрица (блочное или диагональное приближение)
  \State $\tilde{\nabla} L^{(i)} \gets (\hat{g}^{(i)})^{-1} \nabla_{\theta_i} L$
  \State Аппроксимировать символы Кристоффеля $\hat{\Gamma}^{(i)}$ (конечные разности)
  \State Вычислить (приближённо) $\|\hat{R}^{(i)}\|$ --- норму кривизны
\EndFor

\Statex

\State \textbf{Шаг 4: Формирование индикатора аномалий}
\For{каждый слой $i$}
  \State $\hat{A}^{(i)} \gets w_1 \cdot f(\hat{r}_{\text{eff}}^{(i)}) + w_2 \cdot h(\|\hat{R}^{(i)}\|)$
  \If{$\hat{A}^{(i)} > \tau$}
    \State \textbf{Флагировать} слой $i$ как проблемный
  \EndIf
\EndFor

\Statex

\State \textbf{Шаг 5: Адаптивная корректировка}
\State Для проблемных слоёв скорректировать гиперпараметры (шаг обучения, регуляризацию, структуру слоя и т.д.)
\State \Return Индикаторы $\hat{A}^{(i)}$ и рекомендации по корректировке

\end{algorithmic}
\end{algorithm}

\newpage

\section{Рекомендации и предостережения}

Для практического применения алгоритма ULADA (оптимизированной версии) рекомендуется учитывать следующие моменты:
\begin{itemize}
    \item \textbf{Выбор аппроксимаций:} Диагональное приближение гессиана и трасс-оценки являются компромиссом между точностью и скоростью. При необходимости более точного анализа можно увеличить число итераций в оценке или использовать частичный спектральный анализ с итеративными методами.
    \item \textbf{Параллелизация:} Поскольку все этапы анализа для каждого слоя независимы, их выполнение можно эффективно распараллелить на GPU или в распределённых вычислительных системах.
    \item \textbf{Пороговые значения:} Эмпирически подобранные значения весов \( w_1 \), \( w_2 \) и порогового значения \(\tau\) необходимо корректировать в зависимости от архитектуры модели и специфики обучающего набора данных. Рекомендуется проводить предварительные эксперименты для настройки этих параметров. Автоматический подбор пороговых значений будет исследоваться в отдельных работах.
    \item \textbf{Адаптивная коррекция:} При обнаружении проблемных слоёв следует использовать автоматизированную корректировку гиперпараметров (например, изменение шага обучения, введение дополнительной регуляризации) или модификацию архитектуры.
    \item \textbf{Валидация:} Алгоритм следует протестировать на различных типах архитектур (MLP, CNN, трансформеры) для подтверждения его универсальности и корректности диагностики.
\end{itemize}

\section*{Общий вывод}

Алгоритм ULADA (оптимизированная версия) представляет собой строго математически обоснованный метод, который эффективно решает задачу диагностики проблемных слоёв нейронных сетей. Его основное преимущество заключается в возможности идентификации слоёв, негативно влияющих на инференс, за счёт анализа распределения параметрического пространства и динамики оптимизационного процесса. Благодаря применению аппроксимаций и параллелизации, вычислительная сложность алгоритма сводится к линейной \( O(N) \) по числу параметров, что делает его применимым даже для современных крупных моделей. Рекомендации и предостережения, приведённые в данном материале, способствуют корректной настройке и внедрению алгоритма в практическую работу.

\newpage

\section*{Список обозначений и определений}

\begin{itemize}
    \item \(F(x;\theta)\) --- нейросеть, функция, отображающая вход \(x\) в выход, параметризованная \(\theta\).
    \item \(C_i\) --- i-й функциональный блок (слой) нейросети.
    \item \(P_i\) --- модуль параметрического преобразования в i-м слое (умножение на веса, добавление смещения).
    \item \(A_i\) --- модуль активации в i-м слое.
    \item \(\theta_i\) --- параметры i-го слоя.
    \item \(z_i\) --- входные данные для i-го слоя.
    \item \(\varphi\) --- функция агрегации, используемая для свертки выходного вектора в скаляр.
    \item \(S_i(\theta_i)\) --- скалярная функция, определяемая для i-го слоя.
    \item \(g_i = \nabla_{\theta_i} S_i\) --- градиент функции \(S_i\) по параметрам \(\theta_i\).
    \item \(H_i = \nabla^2_{\theta_i} S_i\) --- матрица Гессе для i-го слоя; \(H_i[j,k] = \frac{\partial^2 S_i}{\partial \theta_{i,j}\partial \theta_{i,k}}\).
    \item \(U_i\) --- матрица собственных векторов гессиана \(H_i\).
    \item \(\Lambda_i = \operatorname{diag}(\lambda_{i,1}, \lambda_{i,2}, \dots, \lambda_{i,p_i})\) --- диагональная матрица собственных значений гессиана \(H_i\).
    \item \(\lambda_{i,j}\) --- j-е собственное значение гессиана \(H_i\).
    \item \(p_i\) --- общее количество параметров в i-м слое.
    \item \(r_{\text{eff}}^{(i)}\) --- мера эффективного ранга для i-го слоя, вычисляемая как \(\frac{\left(\sum_{j=1}^{p_i} \lambda_{i,j}\right)^2}{\sum_{j=1}^{p_i}\lambda_{i,j}^2}\).
    \item \(\hat{r}_{\text{eff}}^{(i)}\) --- нормированное значение меры эффективного ранга, \(\frac{r_{\text{eff}}^{(i)} - 1}{p_i - 1}\).
    \item \(g^{(i)}_{ij}(\theta_i)\) --- элемент римановой метрики, задаваемой Фишеровой информацией для i-го слоя.
    \item \(\tilde{\nabla} L^{(i)}\) --- натуральный градиент для i-го слоя, вычисляемый как \(\bigl(g^{(i)}(\theta_i)\bigr)^{-1}\nabla_{\theta_i} L\).
    \item \(L(\theta)\) --- функция потерь нейросети.
    \item \(\gamma^{(i)}\) --- геодезическая линия в параметрическом пространстве i-го слоя.
    \item \(\Gamma^{(i),k}_{jl}\) --- символы Кристоффеля для i-го слоя, вычисляемые как \(\frac{1}{2}\sum_{m}(g^{(i)})^{km}\Bigl(\partial_j g^{(i)}_{lm} + \partial_l g^{(i)}_{jm} - \partial_m g^{(i)}_{jl}\Bigr)\).
    \item \(R^{(i),l}_{\quad ijk}\) --- риманов тензор кривизны для i-го слоя, определяемый как \(\partial_j \Gamma^{(i),l}_{ik} - \partial_i \Gamma^{(i),l}_{jk} + \Gamma^{(i),l}_{jm}\,\Gamma^{(i),m}_{ik} - \Gamma^{(i),l}_{im}\,\Gamma^{(i),m}_{jk}\).
    \item \(\|R^{(i)}\|\) --- норма риманова тензора кривизны для i-го слоя.
    \item \(A^{(i)}\) --- объединённый индикатор аномалий для i-го слоя, вычисляемый как \(w_1 \cdot f\bigl(\hat{r}_{\text{eff}}^{(i)}\bigr) + w_2 \cdot h\bigl(\|R^{(i)}\|\bigr)\).
    \item \(w_1, w_2\) --- весовые коэффициенты, определяющие вклад меры эффективного ранга и кривизны в индикатор аномалий.
    \item \(f(\cdot)\) --- функция нормировки меры эффективного ранга.
    \item \(h(\cdot)\) --- функция нормировки характеристики кривизны.
    \item \(\tau\) --- пороговое значение для индикатора аномалий, выше которого слой считается проблемным.
    \item \(\hat{H}_i\) --- аппроксимированная версия гессиана для i-го слоя.
    \item \(\widehat{\mathrm{tr}}(H_i)\) --- аппроксимированное значение следа гессиана \(H_i\).
    \item \(\widehat{\mathrm{tr}}(H_i^2)\) --- аппроксимированное значение следа квадрата гессиана \(H_i\).
    \item \(\widehat{r}_{\text{eff}}^{(i)}\) --- аппроксимированная мера эффективного ранга для i-го слоя.
    \item \(\hat{g}^{(i)}\) --- аппроксимированная Фишерова матрица для i-го слоя (блочное или диагональное приближение).
    \item \(\hat{\Gamma}^{(i)}\) --- аппроксимированные символы Кристоффеля для i-го слоя.
    \item \(\|\hat{R}^{(i)}\|\) --- аппроксимированная норма риманова тензора кривизны для i-го слоя.
    \item \(\hat{A}^{(i)}\) --- аппроксимированный объединённый индикатор аномалий для i-го слоя.
\end{itemize}

\end{document}