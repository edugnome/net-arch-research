### Куда «копать», если Гессиан уже **10–100 тыс.×10–100 тыс.**

> Ниже перечислены приём-ы и готовые библиотеки, которые позволяют ускорить работу с Гессианом, оставаясь при этом «честными» к собственным числам, кривизне и рангу.

---

#### 1.  Не формируйте матрицу — работайте с **Hessian-vector product (H·v)**

* Автоматическое дифференцирование (reverse-forward composition) даёт H·v за время/память того же порядка, что и градиент.

  * В JAX: `jax.jvp` + `jax.linearize`, в PyTorch: `torch.autograd.functional.hvp`.
  * ICLR-обзор показывает, что методы HVP побеждают классическое построение Гессиана уже при n≈10 000 параметров

* Зная только оператор H·v, можно:

  * получить **k-первых/последних собственных** значений/векторов через Lanczos / LOBPCG;
  * оценить **ранг** и **спектральную плотность** (stochastic Lanczos quadrature).
    Пример готовой реализации — `pytorch-hessian-eigenthings`, где Lanczos и стохастическая степенная итерация уже упакованы .
    Для JAX/TF есть repo Google `spectral-density` с распределённым Lanczos .

---

#### 2.  Если матрица **разреженная** (структурные/физические модели)

1. **Хранение.** CSR/CSC уменьшают память c \~80 ГБ (плотная 100k²×8 байт) до «кол-ва ненулей × 8».
2. **Сборка.**

   * С помощью ADOL-C, Tapenade или Adept можно сразу получить разреженный граф зависимостей.
   * При численной дифференциации — используйте **graph-coloring** (Powell-Toint, Coleman–Moré) — требует O(n) градиентов вместо O(n²) и доказана устойчивая линейная сложность .
3. **Линейная алгебра.**

   * PETSc + SLEPc даёт параллельный Lanczos/Arnoldi/FEAST для больших разреженных матриц. SLEPc 3.23 (март 2025) уже имеет прямую обвязку для Python (`slepc4py`) и GPU-backend .

---

#### 3.  Итерационные решатели и ранние остановки

| Задача                   | Практичный приём                                              |
| ------------------------ | ------------------------------------------------------------- |
| 1–10 крайних λ           | 20-50 итераций Lanczos/LOBPCG на H·v                          |
| Спектр. плотность / ранг | Stochastic Lanczos Quadrature (SLQ) + Hutchinson              |
| Проверка выпуклости      | Достаточно знака **самого минимального** λ (один вызов eigsh) |
| Любая k≪n выборка λ      | FEAST (контурная интеграция) на разреж. матрице               |

При k≪n сложность падает \~O(k·nnz(H)) вместо O(n³).

---

#### 4.  Аппроксимации, когда «чуть-чуть погрешности» допустимо

* **Low-rank + диагональ** (SR1/SRLBFGS) — для слежения за спектром берут диагональ + k-ранговую обновляемую часть; точность первых k λ ≈ o(ε), память O(k n).
* **Krylov-subspace recycling** — если λ нужно обновлять на последовательных итерациях оптимизатора, повторно используйте уже найденные базисы (см. ARPACK/SLEPc `EPSKRYLOVSCHUR`).
* **Mixed precision**: вычисляйте H·v в FP32, а ортогонализацию Lanczos — в FP64 (так делает Google-repo `spectral-density`) ; экономия ×2-×4 памяти без потери значащих цифр λ>1e-3.

---

#### 5.  Практические библиотеки / инструменты «из коробки»

| Ядро          | Библиотека / модуль                      | Что умеет                                           |
| ------------- | ---------------------------------------- | --------------------------------------------------- |
| CPU/GPU       | **PyTorch – hessian-eigenthings**        | Lanczos, степенная, SLQ; GPU HVP                    |
| CPU/GPU       | **JAX – jax.lax + spectral-density**     | распределённый Lanczos, SLQ, mixed precision        |
| MPI / OpenMP  | **PETSc + SLEPc**                        | параллельные собственные, FEAST, нелинейные EVP     |
| C/C++/Fortran | **ARPACK-NG, FEAST, MKL-PARDISO**        | классика для разреженных EVP                        |
| R / C++       | **sparseHessianFD, IPOPT, Ceres-solver** | автомат. разрежённые Гессианы, finite-diff-coloring |

---

#### 6.  Мелкие, но «дорогие» оптимизации

* **Блок-диагональная структура** — часто встречается в батчевых функциях потерь; вычисляйте λ блоков независимо (GPU-батчирование).
* **Параллель HVP** — many-core CPU (OpenMP) или несколько GPU точно масштабируется, т.к. H·v ― чисто умножение.
* **Кэш градиента** при finite difference: ∇f(x) уже есть из обучения — используйте!
* **Порог для ранга**: рангу достаточно λ\_i < ε·λ\_max; ε выбирайте ≈10⁻⁶ для FP64, ≈10⁻³ для FP32.

---

### Что проверить в первую очередь

1. **Есть ли аналитический H·v?** Если да — начинайте с Lanczos/eigsh на H·v.
2. **Hessian разрежённый ≥ 99 %?** Перейдите на CSR + SLEPc.
3. **Нужны только крайние λ?** — не храните Гессиан вовсе.
4. **Память упирается в GPU?** — mixed FP32/64 + SLQ.
5. **Нет AD-кода?** — подключите finite-diff-coloring (ADOL-C, sparseHessianFD).

Следуя этим шагам, можно безболезненно масштабировать задачу с десятков к сотням тысяч параметров, сохраняя контроль над спектром, кривизной и рангом.
